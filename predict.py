import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image
import matplotlib.pyplot as plt
import os
import cv2
import numpy as np

# ============================================================
# 1. é‡æ–°å®šä¹‰ HybridResNet ç½‘ç»œç»“æ„
# (å¿…é¡»ä¸ main03.py ä¸­çš„å®šä¹‰å®Œå…¨ä¸€è‡´ï¼Œå¦åˆ™æ— æ³•åŠ è½½æƒé‡)
# ============================================================
class SEBlock(nn.Module):
    def __init__(self, channel, reduction=16):
        super(SEBlock, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Sequential(
            nn.Linear(channel, channel // reduction, bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(channel // reduction, channel, bias=False),
            nn.Sigmoid()
        )

    def forward(self, x):
        b, c, _, _ = x.size()
        y = self.avg_pool(x).view(b, c)
        y = self.fc(y).view(b, c, 1, 1)
        return x * y.expand_as(x)

class HybridResNet(nn.Module):
    def __init__(self):
        super(HybridResNet, self).__init__()
        
        base_model = models.resnet18(weights=None)
        self.features = nn.Sequential(*list(base_model.children())[:-2])
        self.se_block = SEBlock(512)
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        
        # ğŸ”¥ [Option 1 Update] Statistical Feature Layer
        # Input dim = 8 (Basic Stats) + 64 (Histogram) = 72
        self.stats_fc = nn.Sequential(
            nn.Linear(72, 64), # Expanded neurons
            nn.ReLU(),
            nn.BatchNorm1d(64)
        )
        
        # Regression Head
        self.final_regressor = nn.Sequential(
            nn.Linear(512 + 64, 128),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(128, 1)
        )

    def forward(self, x, hist_vec):
        # --- CNN Branch ---
        feat_map = self.features(x)
        feat_map = self.se_block(feat_map)
        cnn_feat = self.avgpool(feat_map)
        cnn_feat = torch.flatten(cnn_feat, 1)
        
        # --- Statistical Branch ---
        # 1. On-the-fly Basic Stats (8 dims)
        mean_stats = torch.mean(x, dim=[2, 3])
        std_stats = torch.std(x, dim=[2, 3])
        
        mean_a = mean_stats[:, 1:2] 
        mean_b = mean_stats[:, 2:3]
        diff_ab = mean_a - mean_b
        sum_ab  = mean_a + mean_b
        
        basic_stats = torch.cat([mean_stats, std_stats, diff_ab, sum_ab], dim=1)
        
        # 2. ğŸ”¥ Concatenate External Histogram Features (64 dims)
        total_stats = torch.cat([basic_stats, hist_vec], dim=1)
        
        stats_out = self.stats_fc(total_stats)
        
        # --- Fusion ---
        combined = torch.cat([cnn_feat, stats_out], dim=1)
        out = self.final_regressor(combined)
        return out

def get_model(device):
    model = HybridResNet()
    model = model.to(device)
    return model

# ============================================================
# 2. å®šä¹‰æ¨ç†å‡½æ•°
# ============================================================
def predict_temperature(image_path, model_path, device):
    # --- A. åŠ è½½æ¨¡å‹ ---
    print(f"æ­£åœ¨åŠ è½½æ¨¡å‹æƒé‡: {model_path} ...")
    
    model = get_model(device)
    
    if os.path.exists(model_path):
        state_dict = torch.load(model_path, map_location=device)
        model.load_state_dict(state_dict)
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
    else:
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶ {model_path}")
        return None

    model.eval() # åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼

    # --- B. è¯»å–ä¸é¢„å¤„ç†å›¾ç‰‡ ---
    if not os.path.exists(image_path):
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°å›¾ç‰‡æ–‡ä»¶ {image_path}")
        return None

    # 1. ä½¿ç”¨ OpenCV è¯»å– (è§£å†³ä¸­æ–‡è·¯å¾„é—®é¢˜)
    try:
        raw_data = np.fromfile(image_path, dtype=np.uint8)
        img_bgr = cv2.imdecode(raw_data, cv2.IMREAD_COLOR)
        if img_bgr is None: raise ValueError("è§£ç å¤±è´¥")
    except Exception as e:
        print(f"è¯»å–å›¾ç‰‡å¤±è´¥: {e}")
        return None

    # 2. é¢œè‰²ç©ºé—´è½¬æ¢ (å¿…é¡»è½¬ä¸º Labï¼Œä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼)
    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB) # å…ˆè½¬ RGB ä¾›æ˜¾ç¤ºç”¨
    img_lab = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2Lab) # å†è½¬ Lab ä¾›æ¨¡å‹ç”¨

    l, a, b = cv2.split(img_lab)

    # -------------------------------------------------------
    # Image Cleaning (Highlight Removal & Alignment)
    # -------------------------------------------------------
    # 2. Global Brightness Alignment
    l_median_new = np.median(l) 
    shift = 128.0 - l_median_new
    l_aligned = l.astype(np.float32) + shift
    l_aligned = np.clip(l_aligned, 0, 255).astype(np.uint8)

    # 3. Denoising
    a_blur = cv2.GaussianBlur(a, (5, 5), 0)
    b_blur = cv2.GaussianBlur(b, (5, 5), 0)
    
    img_lab_processed = cv2.merge((l_aligned, a_blur, b_blur))
    
    # -------------------------------------------------------
    # ğŸ”¥ [Option 1] Calculate Color Histograms
    # -------------------------------------------------------
    # Calculate histogram for 'a' channel (32 bins)
    hist_a = cv2.calcHist([a_blur], [0], None, [32], [0, 256])
    # Calculate histogram for 'b' channel (32 bins)
    hist_b = cv2.calcHist([b_blur], [0], None, [32], [0, 256])
    
    # Normalize histograms
    cv2.normalize(hist_a, hist_a, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)
    cv2.normalize(hist_b, hist_b, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)
    
    # Flatten and concatenate -> 64-dim vector
    hist_feat = np.concatenate([hist_a, hist_b]).flatten()
    hist_feat = torch.tensor(hist_feat, dtype=torch.float32).unsqueeze(0) # [1, 64]
    hist_feat = hist_feat.to(device)

    # 3. å®šä¹‰ Transform (ä¸è®­ç»ƒä»£ç ä¸­çš„ test transform ä¸€è‡´)
    # æ³¨æ„ï¼šè®­ç»ƒæ—¶å»æ‰äº† ImageNet Normalizeï¼Œåªç”¨äº† Resize å’Œ ToTensor
    transform = transforms.Compose([
        transforms.ToPILImage(), # æ¥å— Lab numpy æ•°ç»„
        transforms.Resize((224, 224)),
        transforms.ToTensor(),   # å½’ä¸€åŒ–åˆ° [0, 1]
    ])
    
    # åº”ç”¨å˜æ¢
    img_tensor = transform(img_lab_processed) 
    img_tensor = img_tensor.unsqueeze(0) # å¢åŠ  Batch ç»´åº¦ [1, 3, 224, 224]
    img_tensor = img_tensor.to(device)

    # --- C. é¢„æµ‹ ---
    with torch.no_grad():
        output = model(img_tensor, hist_feat)
        pred_normalized = output.item()

    # --- D. åå½’ä¸€åŒ– ---
    # å…¬å¼: T = val * 200 + 250
    pred_temp = pred_normalized * 200.0 + 250.0

    return img_rgb, pred_temp

# ============================================================
# 3. ä¸»ç¨‹åºå…¥å£
# ============================================================
if __name__ == '__main__':
    # -------------------------------------------------------------
    # ğŸ”´ è¯·ç¡®ä¿è·¯å¾„æ­£ç¡®
    MODEL_PATH = 'magnesium_hybrid_hist_model.pth'  
    
    # æµ‹è¯•å›¾ç‰‡è·¯å¾„ (æ”¯æŒä¸­æ–‡)
    TEST_IMG_PATH = r"D:\Study\å¤§ä¸‰ä¸Š\science\å¤§åˆ›\JPG-å¤„ç†å›¾\JPG-å¤„ç†å›¾\test\G10_445_10.jpg"
    # -------------------------------------------------------------

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"å½“å‰è®¾å¤‡: {device}")

    # æ‰§è¡Œé¢„æµ‹
    result = predict_temperature(TEST_IMG_PATH, MODEL_PATH, device)

    if result:
        img_vis, temp = result # img_vis æ˜¯ RGB æ ¼å¼ï¼Œæ–¹ä¾¿ matplotlib æ˜¾ç¤º
        
        print("\n" + "="*30)
        print(f"ğŸ“„ å›¾ç‰‡: {os.path.basename(TEST_IMG_PATH)}")
        print(f"ğŸŒ¡ï¸ é¢„æµ‹æ¸©åº¦: {temp:.2f} â„ƒ")
        print("="*30 + "\n")

        # æ˜¾ç¤ºå›¾åƒ
        plt.figure(figsize=(6,6))
        plt.imshow(img_vis)
        plt.title(f"Predicted: {temp:.2f} C")
        plt.axis('off')
        plt.show()